{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying Kinetics Models\n",
    "\n",
    "Testing provides a way to find defects in products such as cars televisions, food, and software.\n",
    "\n",
    "There are two broad objectives for testing. **Validation** determines if the product provides a useful purpose. In terms of kinetics models this means that the model is accurate, and is useful for its intended objectives. For example, to a model for predicting ICU usage for COVID-19 patients might involve: (a) checking its predictions vs. observed future data and (b) estimating the mortality, morbidity, and cost implications resulting from inaccuracies of the model. In general, validation is context and discipline specific.\n",
    "\n",
    "**Verification** is about determining if the product performs according to its specification. For kinetics models, this means that the model dynamics of the model are consistent with what is intended (even if these are not the *correct* dynamics). Validation software engineering typically takes the form of unittests, codes that detect errors in the functioning of software components.\n",
    "\n",
    "This tutorial focuses on verification of kinetics models, ensuring that the intended dynamics are produced by the model. This tutorial is divided into two parts. The first part describes the software setup for doing verification of kinetics models in Jupyter Notebooks. The second part describes an approach to writing kinetics tests using this software setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tellurium as te\n",
    "from teUtils.named_timeseries import NamedTimeseries, TIME\n",
    "from teUtils.timeseries_plotter import TimeseriesPlotter, PlotOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software Setup for Model Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation and Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing is the process by which you exercise your code to determine if it performs as expected. The code you are testing is referred to as the code under test.\n",
    "\n",
    "There are two parts to writing tests.\n",
    "1. invoking the code under test so that it is exercised in a particular way;\n",
    "1. evaluating the results of executing code under test to determine if it behaved as expected.\n",
    "\n",
    "The collection of tests performed are referred to as the test cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing in a Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common data container\n",
    "class CommonData():\n",
    "    # Comtainer for common data\n",
    "    pass\n",
    "global common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common codes used by tests\n",
    "def setUp():\n",
    "    global common\n",
    "    # Initialize common data\n",
    "    common = CommonData()\n",
    "    # Run the simulation\n",
    "    model = '''\n",
    "    model example1\n",
    "      S1 -> S2; k1*S1\n",
    "      S1 = 10\n",
    "      S2 = 0\n",
    "      k1 = 0.1\n",
    "    end\n",
    "    '''\n",
    "    # Collect results of simulation run\n",
    "    common.rr = te.loada(model)\n",
    "    common.data = common.rr.simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "def test1():\n",
    "    global common\n",
    "    setUp()\n",
    "    assert(len(common.data) > 0)\n",
    "def test2():\n",
    "    setUp()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK.\n"
     ]
    }
   ],
   "source": [
    "# Test runner\n",
    "for test in [test1, test2]:\n",
    "    test()\n",
    "print(\"OK.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing A More Sophisticated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonData():\n",
    "    # Comtainer for common data\n",
    "    pass\n",
    "global common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation to be tested\n",
    "def setUp():\n",
    "    global common\n",
    "    # Initialize common data\n",
    "    common = CommonData()\n",
    "    # Run the simulation\n",
    "    model = '''\n",
    "        # Reactions   \n",
    "        J1: S1 -> S2; k1*S1\n",
    "        J2: S2 -> S3; k2*S2\n",
    "        J3: S3 -> S4; k3*S3\n",
    "        J4: S4 -> S5; k4*S4\n",
    "        J5: S5 -> S6; k5*S5;\n",
    "        # Species initializations     \n",
    "        S1 = 10;\n",
    "        k1 = 1; k2 = 2; k3 = 3; k4 = 4; k5 = 5;\n",
    "        S1 = 10; S2 = 0; S3 = 0; S4 = 0; S5 = 0; S6 = 0;\n",
    "        '''\n",
    "    # Collect results of simulation run\n",
    "    common.model = model\n",
    "    common.rr = te.loada(model)\n",
    "    common.data = common.rr.simulate()\n",
    "    common.ts = NamedTimeseries(named_array=common.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "def test1():\n",
    "    global common\n",
    "    setUp()\n",
    "    assert(len(common.data) > 0)\n",
    "def test2():\n",
    "    setUp()\n",
    "    s1_ts = common.ts[\"S1\"]\n",
    "    assert(s1_ts[-1] <= 0.1)  # Last value in timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK.\n"
     ]
    }
   ],
   "source": [
    "# Test runner\n",
    "for test in [test1, test2]:\n",
    "    test()\n",
    "print(\"OK.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout\n",
    "You will be writing tests for ANTIMONY_MODEL\n",
    "1. Create a new Jupyter Notebook\n",
    "1. Create cells for:\n",
    "   1. Common data container\n",
    "   1. Simulation runner for the virus example\n",
    "   1. Test that checks that data are returned from the simulation.\n",
    "1. Create a new test that verifies the columns in the simulation results.\n",
    "   1. Test that the beginning value of S1 is near 10 and its ending value of S1 is near 0.\n",
    "   1. Test that the beginning value of S6 is near 0 and its ending value is near 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Tests for Model Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout\n",
    "Below is a model. Do the following:\n",
    "1. Describe in words the expected dynamics of this model, especially how it differs from the previous model.\n",
    "1. Construct the software setup for testing. Run this simulation for 10 seconds and 100 points.\n",
    "1. Write 5 tests and run them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = '''\n",
    "    # Reactions   \n",
    "    J1: S1 -> S2; k1*S1\n",
    "    J2: S2 -> S3; k2*S2\n",
    "    J3: S3 -> S4; k3*S3\n",
    "    J4: S4 -> S5; k4*S4\n",
    "    J5: S5 -> S3; k5*S5;\n",
    "    # Species initializations     \n",
    "    S1 = 10;\n",
    "    k1 = 1; k2 = 2; k3 = 3; k4 = 10; k5 = 10;\n",
    "    S1 = 10; S2 = 0; S3 = 0; S4 = 0; S5 = 0;\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
