{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing\n",
    "\n",
    "This notebook introduces basic concepts in testing simulation models. There are two parts organized as 15 min of group lecture and 45 minutes of break out.\n",
    "\n",
    "1. Testing basics\n",
    "  - Lecture\n",
    "      - Motivtion\n",
    "      - What is a test and why test\n",
    "      - Setting up tests in a Jupyter Notebook\n",
    "  - Breakout: Set up tests for virus example\n",
    "1. Writing tests\n",
    "  - Lecture\n",
    "    - Smoke test\n",
    "    - One off test\n",
    "    - Boundary test\n",
    "    - Relative tests\n",
    "  - Breakout: Write one of each type of tests for the virus model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tellurium as te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation and Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing is the process by which you exercise your code to determine if it performs as expected. The code you are testing is referred to as the code under test.\n",
    "\n",
    "There are two parts to writing tests.\n",
    "1. invoking the code under test so that it is exercised in a particular way;\n",
    "1. evaluating the results of executing code under test to determine if it behaved as expected.\n",
    "\n",
    "The collection of tests performed are referred to as the test cases. The fraction of the code under test that is executed as a result of running the test cases is referred to as test coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing in a Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common data container\n",
    "class CommonData():\n",
    "    # Comtainer for common data\n",
    "    pass\n",
    "common = CommonData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation to be tested\n",
    "def runSimulation():\n",
    "    # Code under test\n",
    "    model = '''\n",
    "    model example1\n",
    "      S1 -> S2; k1*S1\n",
    "      S1 = 10\n",
    "      S2 = 0\n",
    "      k1 = 0.1\n",
    "    end\n",
    "    '''\n",
    "    # Collect results of simulation run\n",
    "    common.rr = te.loada(model)\n",
    "    common.data = rr.simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "def test1():\n",
    "    assert(len(common.data) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK.\n"
     ]
    }
   ],
   "source": [
    "# Test runner\n",
    "runSimulation()\n",
    "test1()\n",
    "print(\"OK.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout\n",
    "1. Create a new Jupyter Notebook\n",
    "1. Create cells for:\n",
    "   1. Common data container\n",
    "   1. Simulation runner for the virus example\n",
    "   1. Test that checks that data are returned from the simulation\n",
    "   1. Test runner\n",
    "1. Create a new test that verifies the columns in the simulation results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test cases can be of several types. Below are listed some common classifications of test cases.\n",
    "- Smoke test. This is an invocation of the code under test to see if there is an unexpected exception. It's useful as a starting point, but this doesn't tell you anything about the correctness of the results of a computation.\n",
    "- One-shot test. In this case, you call the code under test with arguments for which you know the expected result.\n",
    "- Edge test. The code under test is invoked with arguments that should cause an exception, and you evaluate if the expected exception occurrs.\n",
    "- Pattern test - Based on your knowledge of the calculation (not implementation) of the code under test, you construct a suite of test cases for which the results are known or there are known patterns in these results that are used to evaluate the results returned.\n",
    "\n",
    "Another principle of testing is to limit what is done in a single test case. Generally, a test case should focus on one use of one function. Sometimes, this is a challenge since the function being tested may call other functions that you are testing. This means that bugs in the called functions may cause failures in the tests of the calling functions. Often, you sort this out by knowing the structure of the code and focusing first on failures in lower level tests. In other situations, you may use more advanced techniques called mocking. A discussion of mocking is beyond the scope of this course"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
